# -*- coding: utf-8 -*-
"""Ripple_ravi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15uNRz8cMWBfq3XGpvzLrineI-zLiB-M6
"""

# Utill fns for bigquery
from os import path

from google.cloud import bigquery
from google.oauth2 import service_account
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from sklearn import preprocessing
#from scipy.stats import shapiro
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.cluster.hierarchy import fcluster
from sklearn.cluster import AgglomerativeClustering
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn import metrics
from scipy.spatial.distance import cdist
from google.cloud import bigquery
from google.oauth2 import service_account
import sys
from os import path

from google.colab import auth
auth.authenticate_user()
print('Authenticated')

project_id = 'nimble-valve-257105'

#import xrp_ml_utils.py
start_date='2020-01-16'
end_date='2020-01-16'

#cred_path='C:\\Users\\Francesco\\Desktop\\Projects\\Cal_Hacks\\prova.json'

#Query and query_parameters
query1 = """
Select 
  TIMESTAMP(l.CloseTime) as `TimeStamp`,
  t.Account,t.Destination,t.Fee,t.TxnSignature,t.AmountXRP,t.LedgerIndex,t.TransactionType
FROM
  `xrpledgerdata.fullhistory.transactions`t
JOIN
  `xrpledgerdata.fullhistory.ledgers` l
  on t.LedgerIndex=l.LedgerIndex
where t.TransactionResult = "tesSUCCESS"

AND TIMESTAMP(l.CloseTime) >=TIMESTAMP(@start_date)
AND TIMESTAMP(l.CloseTime) <=TIMESTAMP(@end_date)


ORDER BY TimeStamp

LIMIT 10000000

"""
query_params1 = [
    bigquery.ScalarQueryParameter("start_date", "STRING", start_date),
    bigquery.ScalarQueryParameter("end_date", "STRING", end_date)
]



from google.colab import auth
auth.authenticate_user()
client = bigquery.Client(project=project_id)
#client = bigquery.Client()
client

job_config = bigquery.QueryJobConfig()
job_config.query_parameters = query_params1

a = client.query(query1, job_config=job_config).to_dataframe()

a